## 关键词提取
关键词提取在自然语言处理中也占有很重要的地位，并且很贴近日常生活，特别是在信息爆炸的当下。目前比较受欢迎的是无监督算法，因为不需要维护词表。无监督算法主要由以下几种：
- TF-IDF
- TextRank
- 主题模型算法（LSA，LSI，LDA）
  
### TF-IDF算法
TF(Term Frequency)算法是统计一个词在一篇文档中出现的次数，基本思想是，一个词在文档中出现的次数越多，则其对文档的特性表示也就越强。用数学符号表示：
$$
tf_{ij}=\frac{n_{ij}}{\sum_{k}n_{kj}}
$$
通俗来说就是tf(word)=(word在文档中出现的次数)/(文档总词数)

IDF(Inverse Document Frequency)算法是统计一个词在文档集中出现在几个文档中，基本思想是，如果一个词在越少的文档中出现，则其对文档的区分能力就越强。用数学符号表示：
$idf_{i}=\log(\frac{|D|}{1+|D_{i}|})$
分母加1是为了避免新词在语料库中不存在是分母出现0的情况。这种处理方式叫做拉普拉斯平滑

TF仅衡量词的出现次数，但没有考虑到词对文档的区分能力。相反IDF强调的是词的区分能力，所以一般是将2者结合起来使用。但是如何结合比较好？据学者总结如下效果比较好：
$$
tf\times{idf(i,j)}=tf_{ij}\times{idf_{i}}=\frac{n_{ij}}{\sum_{k}n_{kj}}\times\log(\frac{|D|}{1+|D_{i}|})
$$

通常情况下我们训练一个关键词提取算法需要以下几个步骤
- 加载已有的文档数据集
- 加载停用词表
- 对数据集中的文档进行分词
- 根据停用词表，过滤干扰词
- 根据数据集训练算法
- 对新文档进行分词
- 根据停用词表，过滤干扰词
- 根据训练好的模型提取关键词